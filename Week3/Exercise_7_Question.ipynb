{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n3ln5MT1yg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFAr9cCu15jE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11563
        },
        "outputId": "5693a54d-16ad-4038-fc99-a391621929fc"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "    \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False,\n",
        "    weights=None\n",
        ")\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "pre_trained_model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-12 04:02:43--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 2607:f8b0:400c:c15::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  19%[==>                 ]  16.01M  78.0MB/s               \r        /tmp/incept  55%[==========>         ]  46.16M   114MB/s               \r       /tmp/incepti  88%[================>   ]  74.54M   123MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   132MB/s    in 0.6s    \n",
            "\n",
            "2019-06-12 04:02:43 (132 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebNPUvUH2iZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7947e55b-d532-44e8-887a-474128f413e0"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print(\"Last layer output shape:\", last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Last layer output shape:', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdB3BQ2821Fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('acc') > 0.999):\n",
        "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE0BLcqZ3HDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8520
        },
        "outputId": "42c1b565-890e-41e5-ff0c-05b18cbbe71f"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4ce559a2-9fc9-409f-cddc-52d0b19dc8b3"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-12 04:07:55--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 2607:f8b0:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   117MB/s    in 1.2s    \n",
            "\n",
            "2019-06-12 04:07:56 (117 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-06-12 04:07:58--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.31.128, 2607:f8b0:400c:c10::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.31.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-06-12 04:07:58 (125 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9oK7YNJ3_cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUPyxJi03umI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9f6c7bc7-57d6-4c29-941e-a067dbbafec1"
      },
      "source": [
        "train_horses_dir = os.path.join(train_dir, 'horses')\n",
        "train_humans_dir = os.path.join(train_dir, 'humans')\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "52d8ac54-58fc-4eee-f6c6-f68d3a7d1b7c"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2264
        },
        "outputId": "30211f64-258f-4459-8871-6e5bed959f74"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: 0.0048 - acc: 0.9961\n",
            " - 14s - loss: 0.2895 - acc: 0.8773 - val_loss: 0.0048 - val_acc: 0.9961\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.0507 - acc: 0.9766\n",
            " - 12s - loss: 0.0757 - acc: 0.9727 - val_loss: 0.0507 - val_acc: 0.9766\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.0254 - acc: 0.9883\n",
            " - 12s - loss: 0.0738 - acc: 0.9718 - val_loss: 0.0254 - val_acc: 0.9883\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.0077 - acc: 0.9961\n",
            " - 12s - loss: 0.0603 - acc: 0.9815 - val_loss: 0.0077 - val_acc: 0.9961\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.0519 - acc: 0.9883\n",
            " - 12s - loss: 0.0520 - acc: 0.9786 - val_loss: 0.0519 - val_acc: 0.9883\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.0115 - acc: 0.9883\n",
            " - 12s - loss: 0.0815 - acc: 0.9815 - val_loss: 0.0115 - val_acc: 0.9883\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.0231 - acc: 0.9883\n",
            " - 11s - loss: 0.0212 - acc: 0.9922 - val_loss: 0.0231 - val_acc: 0.9883\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.0156 - acc: 0.9883\n",
            " - 11s - loss: 0.0333 - acc: 0.9903 - val_loss: 0.0156 - val_acc: 0.9883\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.0603 - acc: 0.9805\n",
            " - 12s - loss: 0.0213 - acc: 0.9922 - val_loss: 0.0603 - val_acc: 0.9805\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.0582 - acc: 0.9844\n",
            " - 11s - loss: 0.0259 - acc: 0.9932 - val_loss: 0.0582 - val_acc: 0.9844\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.4623 - acc: 0.9492\n",
            " - 12s - loss: 0.0396 - acc: 0.9903 - val_loss: 0.4623 - val_acc: 0.9492\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.1386 - acc: 0.9727\n",
            " - 11s - loss: 0.0398 - acc: 0.9854 - val_loss: 0.1386 - val_acc: 0.9727\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.2457 - acc: 0.9648\n",
            " - 12s - loss: 0.0256 - acc: 0.9893 - val_loss: 0.2457 - val_acc: 0.9648\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.1690 - acc: 0.9727\n",
            " - 12s - loss: 0.0251 - acc: 0.9942 - val_loss: 0.1690 - val_acc: 0.9727\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.0449 - acc: 0.9844\n",
            " - 11s - loss: 0.0189 - acc: 0.9932 - val_loss: 0.0449 - val_acc: 0.9844\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.3141 - acc: 0.9609\n",
            " - 11s - loss: 0.0398 - acc: 0.9864 - val_loss: 0.3141 - val_acc: 0.9609\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.5717 - acc: 0.9492\n",
            " - 11s - loss: 0.0154 - acc: 0.9981 - val_loss: 0.5717 - val_acc: 0.9492\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.2958 - acc: 0.9570\n",
            " - 11s - loss: 0.0290 - acc: 0.9922 - val_loss: 0.2958 - val_acc: 0.9570\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.3281 - acc: 0.9531\n",
            " - 11s - loss: 0.0364 - acc: 0.9883 - val_loss: 0.3281 - val_acc: 0.9531\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.2404 - acc: 0.9570\n",
            " - 11s - loss: 0.0459 - acc: 0.9883 - val_loss: 0.2404 - val_acc: 0.9570\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.3728 - acc: 0.9531\n",
            " - 11s - loss: 0.0357 - acc: 0.9873 - val_loss: 0.3728 - val_acc: 0.9531\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.3447 - acc: 0.9570\n",
            " - 11s - loss: 0.0200 - acc: 0.9932 - val_loss: 0.3447 - val_acc: 0.9570\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.4248 - acc: 0.9531\n",
            " - 11s - loss: 0.0093 - acc: 0.9971 - val_loss: 0.4248 - val_acc: 0.9531\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.6845 - acc: 0.9453\n",
            " - 11s - loss: 0.0284 - acc: 0.9932 - val_loss: 0.6845 - val_acc: 0.9453\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.2711 - acc: 0.9570\n",
            " - 11s - loss: 0.0353 - acc: 0.9932 - val_loss: 0.2711 - val_acc: 0.9570\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.3844 - acc: 0.9531\n",
            " - 11s - loss: 0.0168 - acc: 0.9942 - val_loss: 0.3844 - val_acc: 0.9531\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 0.3618 - acc: 0.9609\n",
            " - 12s - loss: 0.0117 - acc: 0.9961 - val_loss: 0.3618 - val_acc: 0.9609\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.0975 - acc: 0.9883\n",
            " - 12s - loss: 0.0192 - acc: 0.9932 - val_loss: 0.0975 - val_acc: 0.9883\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.4721 - acc: 0.9570\n",
            " - 11s - loss: 0.0199 - acc: 0.9922 - val_loss: 0.4721 - val_acc: 0.9570\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.3064 - acc: 0.9609\n",
            " - 11s - loss: 0.0197 - acc: 0.9932 - val_loss: 0.3064 - val_acc: 0.9609\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.3088 - acc: 0.9609\n",
            " - 11s - loss: 0.0165 - acc: 0.9951 - val_loss: 0.3088 - val_acc: 0.9609\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.2929 - acc: 0.9609\n",
            " - 11s - loss: 0.0232 - acc: 0.9951 - val_loss: 0.2929 - val_acc: 0.9609\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.6264 - acc: 0.9531\n",
            " - 11s - loss: 0.0079 - acc: 0.9971 - val_loss: 0.6264 - val_acc: 0.9531\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.4235 - acc: 0.9531\n",
            " - 11s - loss: 0.0369 - acc: 0.9912 - val_loss: 0.4235 - val_acc: 0.9531\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.2010 - acc: 0.9648\n",
            " - 11s - loss: 0.0295 - acc: 0.9893 - val_loss: 0.2010 - val_acc: 0.9648\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.1430 - acc: 0.9844\n",
            " - 11s - loss: 0.0119 - acc: 0.9961 - val_loss: 0.1430 - val_acc: 0.9844\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.1864 - acc: 0.9727\n",
            " - 11s - loss: 0.0244 - acc: 0.9942 - val_loss: 0.1864 - val_acc: 0.9727\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.2073 - acc: 0.9727\n",
            " - 11s - loss: 0.0083 - acc: 0.9951 - val_loss: 0.2073 - val_acc: 0.9727\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.0836 - acc: 0.9922\n",
            " - 11s - loss: 0.0208 - acc: 0.9932 - val_loss: 0.0836 - val_acc: 0.9922\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.4351 - acc: 0.9570\n",
            " - 11s - loss: 0.0214 - acc: 0.9922 - val_loss: 0.4351 - val_acc: 0.9570\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.2892 - acc: 0.9609\n",
            " - 11s - loss: 0.0379 - acc: 0.9932 - val_loss: 0.2892 - val_acc: 0.9609\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.1975 - acc: 0.9766\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            " - 11s - loss: 0.0049 - acc: 0.9990 - val_loss: 0.1975 - val_acc: 0.9766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "6a5055f7-7586-4656-c67f-1118c2e019a8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZYiBhEh41Sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}